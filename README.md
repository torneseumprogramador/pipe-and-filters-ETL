# Pipes and Filters - Arquitetura de Software

Este projeto demonstra a implementaÃ§Ã£o da arquitetura **Pipes and Filters** em Python, usando geradores para processamento lazy de dados.

## ğŸ“š O que Ã© Pipes and Filters?

A arquitetura **Pipes and Filters** Ã© um padrÃ£o arquitetural que permite processar dados atravÃ©s de uma sequÃªncia de operaÃ§Ãµes independentes (filtros) conectadas por canais (pipes).

### Componentes Principais:

- **Source (Fonte)**: Gera ou fornece os dados de entrada
- **Filters (Filtros)**: Processam os dados de forma independente
- **Pipes (Tubos)**: Conectam os filtros, passando dados entre eles
- **Sink (Destino)**: Consome os dados processados

### Fluxo de Dados:
```
Source â†’ Filter1 â†’ Filter2 â†’ Filter3 â†’ ... â†’ FilterN â†’ Sink
```

## ğŸ¯ Problemas que Resolve

1. **Processamento Complexo**: Divide operaÃ§Ãµes complexas em etapas simples
2. **ReutilizaÃ§Ã£o**: Filtros podem ser reutilizados em diferentes pipelines
3. **Manutenibilidade**: Cada filtro Ã© independente e fÃ¡cil de testar
4. **Escalabilidade**: Filtros podem ser executados em paralelo
5. **Flexibilidade**: FÃ¡cil reordenar, adicionar ou remover filtros

## âœ… Vantagens

- **Modularidade**: Cada filtro tem uma responsabilidade Ãºnica
- **Testabilidade**: Filtros podem ser testados isoladamente
- **ReutilizaÃ§Ã£o**: Filtros podem ser combinados de diferentes formas
- **Manutenibilidade**: MudanÃ§as em um filtro nÃ£o afetam outros
- **Processamento Lazy**: Dados sÃ£o processados conforme necessÃ¡rio

## âŒ Desvantagens

- **Overhead**: Pode haver overhead de comunicaÃ§Ã£o entre filtros
- **Complexidade**: Para pipelines simples, pode ser excessivo
- **Debugging**: Pode ser difÃ­cil rastrear problemas atravÃ©s do pipeline
- **Performance**: Para datasets pequenos, o overhead pode nÃ£o valer a pena

## ğŸ—ï¸ Estrutura do Projeto

```
pipe-and-filters-ETL/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ filters/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ text_filters.py      # Filtros bÃ¡sicos de texto
â”‚   â”‚   â””â”€â”€ social_filters.py    # Filtros para anÃ¡lise de comentÃ¡rios sociais
â”‚   â”œâ”€â”€ pipes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pipeline.py          # Pipeline base genÃ©rico
â”‚   â”‚   â””â”€â”€ social_pipeline.py   # Pipeline especializado para comentÃ¡rios sociais
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # DemonstraÃ§Ã£o bÃ¡sica do pipeline
â”‚   â””â”€â”€ social_analysis.py       # AnÃ¡lise de comentÃ¡rios sociais
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generator.py             # Gerador de comentÃ¡rios simulados
â”‚   â””â”€â”€ comments_dataset.json    # Dataset de exemplo
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ advanced_usage.py        # Exemplos avanÃ§ados
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_text_filters.py     # Testes dos filtros bÃ¡sicos
â”‚   â”œâ”€â”€ test_pipeline.py         # Testes do pipeline base
â”‚   â””â”€â”€ test_social_filters.py   # Testes dos filtros sociais
â”œâ”€â”€ run.py                       # Script interativo principal
â”œâ”€â”€ setup.py                     # ConfiguraÃ§Ã£o de instalaÃ§Ã£o
â”œâ”€â”€ LICENSE                      # LicenÃ§a MIT
â”œâ”€â”€ .gitignore                   # Arquivo gitignore
â”œâ”€â”€ README.md                    # DocumentaÃ§Ã£o completa
â””â”€â”€ QUICKSTART.md                # Guia de inÃ­cio rÃ¡pido
```

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Python 3.7+
- Make (para usar o Makefile)
- NÃ£o sÃ£o necessÃ¡rias bibliotecas externas (Python puro)

### ğŸ¯ ExecuÃ§Ã£o RÃ¡pida com Makefile (Recomendado)
```bash
# Navegar para o diretÃ³rio do projeto
cd pipe-and-filters-ETL

# Ver todos os comandos disponÃ­veis
make help

# ConfiguraÃ§Ã£o inicial completa
make setup

# DemonstraÃ§Ã£o completa (gera dados + executa demo)
make demo

# InicializaÃ§Ã£o rÃ¡pida completa
make quick-start
```

### ğŸ”§ Comandos Principais do Makefile
```bash
# GeraÃ§Ã£o de dados
make generate-data          # Gera 100 comentÃ¡rios
make generate-data-small    # Gera 20 comentÃ¡rios (testes)
make generate-data-large    # Gera 500 comentÃ¡rios (demo)

# ExecuÃ§Ã£o de demonstraÃ§Ãµes
make basic-demo            # Pipeline bÃ¡sico
make social-analysis       # AnÃ¡lise de comentÃ¡rios sociais
make examples              # Exemplos avanÃ§ados
make demo                  # DemonstraÃ§Ã£o completa
make run                   # Script interativo

# Testes e qualidade
make test                  # Executa todos os testes
make test-quick           # Testes rapidamente
make test-coverage        # Testes com cobertura
make lint                 # VerificaÃ§Ã£o de cÃ³digo
make format               # FormataÃ§Ã£o de cÃ³digo
make check-all            # Todos os checks

# ManutenÃ§Ã£o
make clean                # Limpa arquivos temporÃ¡rios
make install              # Instala dependÃªncias
make validate             # Valida estrutura do projeto
make show-status          # Mostra status atual
```

### ğŸ“ ExecuÃ§Ã£o Manual (Alternativa)
```bash
# 1. Gerar dados simulados de comentÃ¡rios
python data/generator.py -n 100

# 2. Executar demonstraÃ§Ã£o bÃ¡sica
python src/main.py

# 3. Executar anÃ¡lise de comentÃ¡rios sociais
python src/social_analysis.py

# 4. Usar script interativo
python run.py
```

### Executar os Testes
```bash
# Executar todos os testes
python -m unittest discover tests

# Executar testes especÃ­ficos
python -m unittest tests.test_text_filters
python -m unittest tests.test_pipeline

# Executar com mais detalhes
python -m unittest discover tests -v
```

## ğŸ”§ ImplementaÃ§Ã£o

### Filtros Implementados

#### Filtros BÃ¡sicos de Texto:
1. **`remove_extra_spaces`**: Remove espaÃ§os extras e mÃºltiplos
2. **`filter_numeric_strings`**: Filtra apenas strings numÃ©ricas
3. **`convert_to_integers`**: Converte strings para inteiros
4. **`filter_greater_than`**: Filtra nÃºmeros maiores que um limite

#### Filtros para AnÃ¡lise de ComentÃ¡rios Sociais:
5. **`clean_text`**: Limpa e normaliza texto dos comentÃ¡rios
6. **`filter_by_sentiment`**: Filtra por sentimento (positivo/negativo)
7. **`filter_by_language`**: Filtra por idioma detectado
8. **`filter_by_country`**: Filtra por paÃ­ses especÃ­ficos
9. **`filter_by_likes_threshold`**: Filtra por faixa de likes
10. **`add_engagement_score`**: Calcula score de engajamento
11. **`detect_spam`**: Detecta comentÃ¡rios spam
12. **`normalize_user_names`**: Normaliza nomes de usuÃ¡rio
13. **`add_text_metrics`**: Adiciona mÃ©tricas de texto

### Pipeline de Exemplo

#### Pipeline BÃ¡sico de Texto:
O projeto implementa um pipeline que:
1. Remove espaÃ§os extras das strings
2. Filtra apenas strings numÃ©ricas
3. Converte strings para inteiros
4. Filtra apenas nÃºmeros maiores que 10

#### Pipeline de AnÃ¡lise de ComentÃ¡rios Sociais:
Pipeline especializado que:
1. Limpa e normaliza texto dos comentÃ¡rios
2. Normaliza nomes de usuÃ¡rio
3. Adiciona mÃ©tricas de texto
4. Calcula score de engajamento
5. Detecta comentÃ¡rios spam
6. Filtra por sentimento, idioma, paÃ­s ou likes

### Exemplo de Uso

#### Pipeline BÃ¡sico:
```python
from src.pipes.pipeline import create_text_processing_pipeline

# Cria pipeline prÃ©-configurado
pipeline = create_text_processing_pipeline()

# Dados de entrada
input_data = ["  123  ", "  abc  ", "  456  "]

# Processa os dados
result = pipeline.execute(iter(input_data))
print(result)  # [123, 456]
```

#### Pipeline de AnÃ¡lise Social:
```python
from src.pipes.social_pipeline import create_sentiment_analysis_pipeline

# Cria pipeline para anÃ¡lise de sentimentos
pipeline = create_sentiment_analysis_pipeline().add_sentiment_filter("positive")

# Carrega comentÃ¡rios de arquivo JSON
with open('data/comments_dataset.json', 'r') as f:
    comments = json.load(f)

# Analisa comentÃ¡rios positivos
positive_comments = pipeline.execute(iter(comments))
print(f"Encontrados {len(positive_comments)} comentÃ¡rios positivos")
```

## ğŸ§ª Testes

O projeto inclui testes unitÃ¡rios abrangentes para:

- **Filtros individuais**: Testa cada filtro isoladamente
- **Pipeline**: Testa a funcionalidade de conexÃ£o dos filtros
- **Casos extremos**: Entrada vazia, tipos mistos, etc.
- **Processamento lazy**: Verifica que os dados sÃ£o processados conforme necessÃ¡rio

## ğŸ” CaracterÃ­sticas TÃ©cnicas

- **Processamento Lazy**: Usa geradores Python para processar dados conforme necessÃ¡rio
- **Tipagem**: Inclui type hints para melhor documentaÃ§Ã£o e IDE support
- **Iteradores**: Todos os filtros trabalham com iteradores para eficiÃªncia
- **Modularidade**: Cada filtro Ã© independente e testÃ¡vel
- **Encadeamento**: Pipeline suporta encadeamento de mÃ©todos

## ğŸ“– Casos de Uso

Esta arquitetura Ã© ideal para:

- **ETL (Extract, Transform, Load)**: Processamento de dados
- **Streaming de dados**: Processamento de dados em tempo real
- **Pipeline de ML**: PrÃ©-processamento de dados
- **AnÃ¡lise de logs**: Filtragem e transformaÃ§Ã£o de logs
- **Processamento de arquivos**: ValidaÃ§Ã£o e transformaÃ§Ã£o de dados
- **AnÃ¡lise de redes sociais**: Processamento de comentÃ¡rios e sentimentos
- **ModeraÃ§Ã£o de conteÃºdo**: DetecÃ§Ã£o de spam e conteÃºdo inadequado
- **AnÃ¡lise de engajamento**: MÃ©tricas de interaÃ§Ã£o e performance
- **AnÃ¡lise geogrÃ¡fica**: Filtragem por localizaÃ§Ã£o e regiÃ£o
- **AnÃ¡lise multilingue**: Processamento de conteÃºdo em diferentes idiomas

## ğŸ¤ Contribuindo

Para contribuir com o projeto:

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature
3. Implemente suas mudanÃ§as
4. Adicione testes para novas funcionalidades
5. Execute os testes existentes
6. FaÃ§a commit das mudanÃ§as
7. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto Ã© de cÃ³digo aberto e estÃ¡ disponÃ­vel sob a licenÃ§a MIT.

## ğŸ“ Aprendizado

Este projeto serve como exemplo educacional para:

- Entender arquiteturas de software
- Aprender padrÃµes de design
- Praticar programaÃ§Ã£o funcional com Python
- Implementar processamento de dados eficiente
- Desenvolver cÃ³digo testÃ¡vel e modular
